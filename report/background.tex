In this section we give the background needed to better understand the upcoming part of this report. 

\section {Weak Memory}
As explained in the introduction, we cannot expect a sequentially consistent behavior from any parallel program. 
%However, dealing with the behaviors introduced by weak memory is cumbersome and error-prone. Libraries hence contain all the necessary locks and synchronization tools, that if used properly ensure a sequentially consistent behavior. Hence only those writing those libraries have to deal with weak memory.
We have to deal with all the behaviors introduced by weak memory. We will now explain in some more details how those work.

We consider two type of memory locations: atomics and non atomics. Non atomics are the one we are the default, the ones we use in most programs. However, they are not adapted for concurent access: if two threads try to access a non atomic location at the same time, and at least one of them is writing, the behavior of both threads is undefined. Hence we cannot use this kind of locations in a concurrent environment without making sure that no such racy access can happen. 

This synchronization is done using atomics. Operations on those locations are atomic: we can think of them as happening in an instant, so that nothing can happen at the same time (since they took so little time). Hence the race situation described above, with a thread reading from an atomic location at the same time as another thread is writing to it, cannot happen. As both operations are atomic, either the read happens first, or the write does. However, those atomic operations are more expensive than non atomic ones. Hence we only use them to create the necessary synchronization to avoid data races.

\subsection{Synchronization on atomics}
While atomics are unaffected by races, we still cannot trust them for sequential consistency. Due to potential reorderings by the compiler or the processor, or delayed synchronization of different caches, \texttt{a = 1; b = 1} may become \texttt{b = 1, a = 1}. We hence need some construct to enforce ordering between memory accesses, be them atomic or non atomic. We use fences for that. We here only mention three of them: sequentially consistent (SC) ones, acquire (Acq) ones and release (Rel) ones. The synchronization they offer is summarized in Figure~\ref{fig:fence}. The sequentially consistant fence is the stronger of them all: it forbids any reodering around it. However, it is quite expensive. Hence, most of the time we try to use weaker fences, that take less time and operations to enforce. The release fence ensures that any read or write before it will not be re-ordered after the writes after it. Hence reading a value written by a write after this fence guarantees that all memory operations that happened before this fence are visible as well: they were \emph{released} with the write.

\begin{figure}
\begin{tabular}{ccc}
\begin{tikzpicture}[font=\sffamily]
    \node (f) at (0,0) {SC fence};
    \node (rA) [above left=1cm and 0.1cm of f]  {Read};% 2cm below, 1cm to the left (optional)
    \node (wA) [above right=1cm and 0.1cm of f] {Write};
    \node (rB) [below left=1cm and 0.1cm of f]  {Read};
	\node (wB) [below right=1cm and 0.1cm of f] {Write};
    \draw [semithick,->] (rA) -- (f);
    \draw [semithick,->] (wA) -- (f);
    \draw [semithick,->] (f) -- (rB);
    \draw [semithick,->] (f) -- (wB);
\end{tikzpicture}
		& 
		\begin{tikzpicture}[font=\sffamily]
    \node (f) at (0,0) {Acq fence};
    \node (rA) [above= 1cm of f]  {Read};% 2cm below, 1cm to the left (optional)
    %\node (wA) [above right=1cm and 1cm of f] {Write};
    \node (rB) [below left=1cm and 0.1cm of f]  {Read};
	\node (wB) [below right=1cm and 0.1cm of f] {Write};
    \draw [semithick,->] (rA) -- (f);
    %\draw [semithick,->] (wA) -- (f);
    \draw [semithick,->] (f) -- (rB);
    \draw [semithick,->] (f) -- (wB);
\end{tikzpicture}
	
		&
\begin{tikzpicture}[font=\sffamily]
    \node (f) at (0,0) {Rel fence};
    \node (rA) [above left=1cm and 0.1cm of f]  {Read};% 2cm below, 1cm to the left (optional)
    \node (wA) [above right=1cm and 0.1cm of f] {Write};
    %\node (rB) [below left=1cm and 1cm of f]  {Read};
	\node (wB) [below=1cm of f] {Write};
    \draw [semithick,->] (rA) -- (f);
    \draw [semithick,->] (wA) -- (f);
    %\draw [semithick,->] (f) -- (rB);
    \draw [semithick,->] (f) -- (wB);
\end{tikzpicture}
	
\end{tabular}
\caption{Fences synchronization}
\label{fig:fence}
\end{figure}

The easiest way to think about the way those fences work, is to consider that the order in which different operations appear in the program have no impact on their actual execution order unless we use some special construct that enforces an order. This is kind of the way the \emph{happen-before} relation defined in the C11 standard works \cite{C11}: we assume no order, and define using fences, operations reading on the same variable, ... a transitive relation that explicits the order that is preserved during the actual execution. Using this way of thinking, a release array creates arrows from all read and writes above it to itself, and from itself to all writes below it.

On top of the fences, we can enforce synchronization by doing a \emph{release write} or an \emph{acquire read}. Here the synchronization is slightly weaker than when using a fence, as shown on Figure~\ref{fig:readWrite}. For instance, the release write only forbids reordering of previous read or writes with itself, and not with all writes after itself. 
\begin{figure}
\begin{tabular}{cc}
		\begin{tikzpicture}[font=\sffamily]
    \node (f) at (0,0) {Read Acquire};
    %\node (rA) [above= 1cm of f]  {Read Acquire};% 2cm below, 1cm to the left (optional)
    %\node (wA) [above right=1cm and 1cm of f] {Write};
    \node (rB) [below left=1cm and 0.1cm of f]  {Read};
	\node (wB) [below right=1cm and 0.1cm of f] {Write};
    %\draw [semithick,->] (rA) -- (f);
    %\draw [semithick,->] (wA) -- (f);
    \draw [semithick,->] (f) -- (rB);
    \draw [semithick,->] (f) -- (wB);
\end{tikzpicture}
	
		&
\begin{tikzpicture}[font=\sffamily]
    \node (f) at (0,0) {Release Write};
    \node (rA) [above left=1cm and 0.1cm of f]  {Read};% 2cm below, 1cm to the left (optional)
    \node (wA) [above right=1cm and 0.1cm of f] {Write};
    %\node (rB) [below left=1cm and 1cm of f]  {Read};
	%\node (wB) [below=1cm of f] {Write};
    \draw [semithick,->] (rA) -- (f);
    \draw [semithick,->] (wA) -- (f);
    %\draw [semithick,->] (f) -- (rB);
    %\draw [semithick,->] (f) -- (wB);
\end{tikzpicture}
	
\end{tabular}
\caption{Release writes and acquire reads synchronization}
\label{fig:readWrite}
\end{figure}


\subsection{Data races}
Using the \emph{happen before} relation we gave an outline of above, it is easy to get a nicer intuition of data races: an program is racy if it contains two non atomic operations on a non atomic location, one of which is a write, that are not ordered with happen before.

%We show in Figure~\ref{fig:flag} an example of a racy execution and a non racy one. In the non racy one, we use the fact that reading a value from an earlier write creates an ordering between the two operations, as well as the fact that conditionnals enforce ordering.

Note that the bits of definition of \emph{happen before} given here are in no way formal, and simply aims at giving a better intuition of the synchronization mechanisms we will study in this report.

\section{Formalizing weak memory}
We gave above some intuition of synchronization. However, this is far from enough to build any proof for a program, let alone build a verification tool. Quite a few formalization have been proposed as a formal definition of what can happen in this context. We will here use FSL++\cite{fsl}. This separation logic formalizes a strenghtening of what the C11 standard describes. The details of this strenghtening are discussed in \cite{fsl}.

Let us first give an intuition of how this logic works. One further simplification imposed by this logic is that all locations are either atomic or non atomic (whereas in C++ a cast could change that).

\subsection{Atomics as exchange points}
As we explained in the previous section, we usually use atomics to protect non atomic locations from data races. Atomics are simply here to transfer some information between threads, to ensure proper synchronization, and let non atomics do the actual program work. This is for instance what we do if we build a parallel program using locks: the atomics within the locks enforce proper synchronization, and we use the rest of the variables to do all the computations we are interested in. 

FSL++ builds builds on this idea of atomics as mere signal senders between threads. For each atomic variable, one can define a location invariant $\mathcal{Q}: v \mapsto \mathcal{Q}(v)$. This invariant maps each value that can be read or stored in the atomic variable to some predicate. Now when writing to an atomic location a value $v$, a thread has to give up $\mathcal{Q}(v)$, whereas when it reads $v$ from this location, it gains $\mathcal{Q}(v)$. Some more rules are needed to ensure that when reading twice the same value from a location, we do not get twice the predicate. These rules are explained in more details in the parts of this report they are relevant to.

\subsection{Ownership}
We just saw that in FSL++ we use atomic locations to exchange predicates between threads, but what kind of predicates? We here introduce the notion of \emph{ownership}. When a new non atomic location $l$ is allocated by a thread, the thread get full ownership of it, noted $l^1$\footnote{This notation is slightly different from the one used in \cite{fsl}, mostly to make formulas shorter in this report, and easier to fit on page.}. This full ownership allows the thread to read or write to the location. This ownership can then be transfered to another thread through an atomic location for example. It could also be split in two (or more) parts: $l^{0.5} * l^{0.5}$. Some of this fractional permission can then be sent to another thread, while the other part of it is kept. With this partial permission, a thread can only read from the non atomic location $l$, so as to forbid data races. As the total amount of ownership is $1$, and ownership cannot be created except when a variable is allocated, there can always be at most one thread having full permission, and if this is the case no other thread has any amount of permission. Hence we make sure that at most one thread can write to a variable at any given point, and if this is the case, no other thread can read concurrently to the variable. 

In \cite{fsl}, a notion of modality is also defined, to properly account for fences, however in this report, we never need to use those modalities, as synchronization always happen in such a way that no modality is present in the proof presented. We will hence not explain more about them here.

\subsection{Ghost states}
On top of ownership, the predicates stored in the location invariants of atomic locations can contains reference to a \emph{ghost state}. A ghost state is simply a special variable, that we use as a helper in the proof, to model some information that cannot be translated simply using ownership. When defining this special variable, we also define the domain in which it takes its values. Carefully choosing this domain allows to model complex protocols, that could not be modelled using FSL++ otherwise. In this report, we will only use one kind of ghost state domain, the entity  fractional-counting (EFC) permission structure. It was defined in \cite{gaurav}, and allows to prove with few ghost locations the examples that were studied in \cite{gaurav}.

The EFC permission structure is defined as 
\[\left(\left(\mathbb{N}_{>0} \times \mathbb{Q}_{>0} \times\{-,+\}\right) \cup\left\{(a, 0)^{+},(a, 0)^{-} | a \in \mathbb{N}\right\}, \oplus,(0,0)^{+},(0,0)^{-}\right)\]
with the partial commutative and associative operation $\oplus$ defined as 
\[\begin{array}{r}
{(c, d)^{+} \oplus(a, b)^{-} :=(a, b)^{-} \oplus(c, d)^{+} :=
\left\{\begin{array}{cl}
&{\text { if } a-c }{\geq 0 \text { and }} \\ 

{(a-c, b-d)^{-}} & {b-d }{\geq 0 \text { and }} 
\\ &({a-c}  {=0 \Rightarrow} {b-d}  {=0})\\

{\text { undefined }}&{{otherwise }}
\end{array}\right.} \\ 
\end{array}
\]
		
\[(a, b)^{+} \oplus(c, d)^{+} :=(a+c, b+d)\]

\[(a, b)^{-} \oplus(c, d)^{-} :=\text {undefined }\]

The idea of this permission structure is to have a single source permission $(c, s)^-$, and some amount of tokens $(1, s)^+$. The operation $\oplus$ being partial for two values with $-$ ensures that there can only be one source permission. The idea of this permission structure is to correspond to the intuition one can have of an atomic location $l$ protecting a non atomic location $d$. We can then have in the location invariant of $l$ the source permission, while threads that change the value of the atomic location gain or give up some tokens. The tokens are usually of the form $(1, s)^+$: they are hence unsplitable (because of the 1), and $s$ usually specifies the amount of permission the thread owns to $d$. For instance a token $(1, 1)^+$ specifies write permission. As $\oplus$ is not defined for some values, a thread owning $(1, 1)^+$ ensures that the source must be $(c, 1)^-$, recording the fact that there is no permission left.

We explained above the idea of the tokens being related to an amount of permission. The tokens themselves do not give any permission to a thread, by by defining carefully the invariant for $l$, we can make sure that a thread can only gain permission at the same time as gaining a token. This can then be used in the proof, by reasoning on the values of tokens and sources, to prove that the program respects the invariant.

\subsection{Token-based reasoning in Viper}
In \cite{pascal}, Wiesman et al. abstracted some of the complexity of FSL++ and the EFC permission structure, to be able to implement a tool that could be used in Viper, and automate as much as possible of the reasoning, for concurrent C++ programs. Token based reasoning unifies the permission to a location $d^s$, and the token $(1, s)^+$, into a new kind of token. It also removes the exact amount of the permission $s$, replacing it with either \emph{write, read} or \emph{none}. The possible tokes are hence 
\[\texttt { Tok }(\text {loc}, n, \tau) \text { where } n \in \mathbb{N}_{>0} \text { and } \tau \in\{ {none, read, write}\}\]
and the source is now 
\[\texttt{Src}(l o c, n, \tau) \text { where } n \in \mathbb{N} \geq 0, \text { and } \tau \in\{ {none, read, write}\}\]

This allows for simpler automation rules, at the price of some approximation, as we will see in Section~\ref{sec1}.

